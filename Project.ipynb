{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9adb4e4",
   "metadata": {},
   "source": [
    "### Подготовьте гистограммы по самым популярным жанрам, режиссерам, нац. принадлежностям фильмов, годам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2469ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.classify import DecisionTreeClassifier, NaiveBayesClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84ea674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07406a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Wiki Page'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd26428",
   "metadata": {},
   "source": [
    "В анализируемом датасете 34886 строк. Всего 8 столбцов, все поля с типом данных object, за исключением поля Release Year. Пропущенные значения есть только в столбце Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a202caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(df.columns):\n",
    "    print(\"Уникальных значений в столбце {0} : {1}\".format(i, len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dedd097",
   "metadata": {},
   "source": [
    "Так как цель проекта определить жанр, то отберем строки, где точно известен жанр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Genre']!='unknown']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6289d",
   "metadata": {},
   "source": [
    "На мой взгляд при определении жанра важен режисер, удалим значения с Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Director']!='Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea540339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Release Year\")[\"Release Year\"].count().sort_index(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_col in [\"Genre\", \"Origin/Ethnicity\", \"Director\", \"Release Year\"] :\n",
    "    d = df.copy()\n",
    "    d['plus'] = d[i_col]\n",
    "    if i_col == \"Release Year\":\n",
    "        data = d.groupby(i_col)['plus'].count().sort_index(ascending=False).reset_index().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax = sns.barplot(data=data, x=data[i_col], y=data['plus'], ax=ax)\n",
    "    else:\n",
    "        data = d.groupby(i_col)['plus'].count().sort_values(ascending=False).reset_index().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax = sns.barplot(data=data, x=data['plus'], y=data[i_col], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Из всего датасета самый популярный жанр драма-почти 6000 фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самые попоулярные жанры в Америке\n",
    "d = df.copy()\n",
    "d['plus'] = d['Origin/Ethnicity']\n",
    "data = d.groupby(\"Genre\")['plus'].count().sort_values(ascending=False).reset_index().head(10)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax = sns.barplot(data=data, x=data['plus'], y=data[\"Genre\"], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea85631",
   "metadata": {},
   "source": [
    "разделим столбец Genre с несколькими жанрами и посмотрим как изменятся объемы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e729683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ef61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = WordPunctTokenizer()\n",
    "# df_copy['Genre'] = df_copy['Genre'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "# df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# movies_df = movies_df[(movies_df[\"Origin/Ethnicity\"]==\"American\") | (movies_df[\"Origin/Ethnicity\"]==\"British\")]\n",
    "# movies_df = movies_df[[\"Plot\", \"Genre\"]]\n",
    "# drop_indices = movies_df[movies_df[\"Genre\"] == \"unknown\" ].index\n",
    "# movies_df.drop(drop_indices, inplace=True)\n",
    "\n",
    "# Заменим сокращенные жанры: 1) \"sci-fi\" на \"science fiction\" и 2) \"romantic comedy\" на \"romance\"\n",
    "df_copy[\"Genre\"].replace({\"sci-fi\": \"science fiction\", \"romantic comedy\": \"romance\"}, inplace=True)\n",
    "\n",
    "# Выберем самые популярные жанры\n",
    "shortlisted_genres = df_copy[\"Genre\"].value_counts().reset_index(name=\"count\").query(\"count > 100\")[\"index\"].tolist()\n",
    "df_copy = df_copy[df_copy[\"Genre\"].isin(shortlisted_genres)].reset_index(drop=True)\n",
    "\n",
    "# Выберем случайным образом 1 жанр из тех, где указано несколько жанров\n",
    "df_copy = df_copy.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Sample roughly equal number of movie plots from different genres (to reduce class imbalance issues)\n",
    "df_copy = df_copy.groupby(\"Genre\").head(400).reset_index(drop=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_copy[\"genre_encoded\"] = label_encoder.fit_transform(df_copy[\"Genre\"].tolist())\n",
    "\n",
    "# df_copy = df_copy[[\"Plot\", \"Genre\", \"genre_encoded\"]]\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0579727",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_col in [\"Genre\", \"Origin/Ethnicity\", \"Director\", \"Release Year\"] :\n",
    "    d = df_copy.copy()\n",
    "    d['plus'] = d[i_col]\n",
    "    if i_col == \"Release Year\":\n",
    "        data = d.groupby(i_col)['plus'].count().sort_index(ascending=False).reset_index().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax = sns.barplot(data=data, x=data[i_col], y=data['plus'], ax=ax)\n",
    "    else:\n",
    "        data = d.groupby(i_col)['plus'].count().sort_values(ascending=False).reset_index().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax = sns.barplot(data=data, x=data['plus'], y=data[i_col], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36497080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f038fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa9618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4aa4875",
   "metadata": {},
   "source": [
    "### 2.Подготовьте sentiment analysis по отзывам (используя  nltk.classify) и оцените, как распределяется sentiment по актерам, режиссерам и жанрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f27c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcc3ae",
   "metadata": {},
   "source": [
    "загружаем отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "253e0d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"IMDB_Dataset.csv.zip\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81398fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[a, wonderful, little, production, ., &lt;, br, /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, there, ', s, a, family, where, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, ', s, \", love, in, the, time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, my, all, -, time, favorite, movie, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, show, was, an, amazing, ,, fresh, &amp;, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[if, you, like, original, gut, wrenching, laug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                        review_token  \n",
       "0  [one, of, the, other, reviewers, has, mentione...  \n",
       "1  [a, wonderful, little, production, ., <, br, /...  \n",
       "2  [i, thought, this, was, a, wonderful, way, to,...  \n",
       "3  [basically, there, ', s, a, family, where, a, ...  \n",
       "4  [petter, mattei, ', s, \", love, in, the, time,...  \n",
       "5  [probably, my, all, -, time, favorite, movie, ...  \n",
       "6  [i, sure, would, like, to, see, a, resurrectio...  \n",
       "7  [this, show, was, an, amazing, ,, fresh, &, in...  \n",
       "8  [encouraged, by, the, positive, comments, abou...  \n",
       "9  [if, you, like, original, gut, wrenching, laug...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "reviews['review_token'] = reviews['review'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c97a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tokens):\n",
    "    ''' This function takes list of words in a sentence as input \n",
    "    and returns a vector of size of filtered_vocab.It puts 0 if the \n",
    "    word is not present in tokens and count of token if present.'''\n",
    "    vector=[]\n",
    "    for w in filtered_vocab:\n",
    "        vector.append(tokens.count(w))\n",
    "    return vector\n",
    "def unique(sequence):\n",
    "    '''This functions returns a list in which the order remains \n",
    "    same and no item repeats.Using the set() function does not \n",
    "    preserve the original ordering,so i didnt use that instead'''\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "#list of special characters.You can use regular expressions too\n",
    "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\",\"-\",\"!\",\"/\",\"<\",\"&\",\"'\", \"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c52414a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews['review_token'] = reviews['review_token'].apply(lambda x: i if i in special_char else 0 for i in reviews['review_token'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b0d095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_num, i_str in enumerate(reviews['review_token']):\n",
    "    filtered_text = []\n",
    "    for i_word in i_str:\n",
    "        if (i_word.isalpha() and i_word not in stops):\n",
    "            filtered_text.append(i_word)\n",
    "    reviews['review_token'][i_num] = filtered_text\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30793904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_token</th>\n",
       "      <th>code_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, family, little, boy, jake, thinks,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, mattei, love, time, money, visually, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, movie, right, good, job, creative, o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[going, disagree, previous, comment, side, mal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                            review_token  code_sent  \n",
       "0      [one, reviewers, mentioned, watching, oz, epis...          1  \n",
       "1      [wonderful, little, production, br, br, filmin...          1  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...          1  \n",
       "3      [basically, family, little, boy, jake, thinks,...          0  \n",
       "4      [petter, mattei, love, time, money, visually, ...          1  \n",
       "...                                                  ...        ...  \n",
       "49995  [thought, movie, right, good, job, creative, o...          1  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...          0  \n",
       "49997  [catholic, taught, parochial, elementary, scho...          0  \n",
       "49998  [going, disagree, previous, comment, side, mal...          0  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...          0  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['code_sent'] = reviews['sentiment'].map({'negative':0, 'positive':1})\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37575b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5af2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "zipfile = 'IMDB_Movies_2021.db.zip'\n",
    "z = ZipFile(zipfile)\n",
    "z.infolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe05655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"IMDB_Movies_2021.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create your connection.\n",
    "cnx = sqlite3.connect('IMDB_Movies_2021.db')\n",
    "\n",
    "reviews = pd.read_sql_query(\"tables\", cnx)\n",
    "# reviews = pd.read_csv(\"IMDB_Movies_2021.db.zip\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245b5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f55a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d183b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаю отзывы, джойню по году/названию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ae99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поле отзывы токенизирую, стем, лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9851c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяю выборку на test train по очереди обучаю модели по актерам, режиссерам и жанрам\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = reviews.drop('code_sent', axis=1)\n",
    "X = reviews['review_token']\n",
    "y = reviews['code_sent']\n",
    "\n",
    "X_train , X_test, y_train , y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1fc9ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39mSklearnClassifier(\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train)\n\u001b[1;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39maccuracy(classifier, X_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "classifier = nltk.classify.SklearnClassifier(DecisionTreeClassifier())\n",
    "classifier.train(X_train, y_train)\n",
    "accuracy = nltk.classify.accuracy(classifier, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caf38a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LogisticRegression' from 'nltk' (/Users/olgakamskaa/opt/anaconda3/lib/python3.9/site-packages/nltk/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39mSklearnClassifier(LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m      3\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LogisticRegression' from 'nltk' (/Users/olgakamskaa/opt/anaconda3/lib/python3.9/site-packages/nltk/__init__.py)"
     ]
    }
   ],
   "source": [
    "from nltk import LogisticRegression\n",
    "classifier = nltk.classify.SklearnClassifier(LogisticRegression(C=1000))\n",
    "classifier.train(X_train, y_train)\n",
    "accuracy = nltk.classify.accuracy(classifier, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "136bc26b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BernoulliNB' from 'nltk' (/Users/olgakamskaa/opt/anaconda3/lib/python3.9/site-packages/nltk/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BernoulliNB\n\u001b[1;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39mSklearnClassifier(BernoulliNB(binarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m      3\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain(X_train, y_train)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BernoulliNB' from 'nltk' (/Users/olgakamskaa/opt/anaconda3/lib/python3.9/site-packages/nltk/__init__.py)"
     ]
    }
   ],
   "source": [
    "from nltk import BernoulliNB\n",
    "classifier = nltk.classify.SklearnClassifier(BernoulliNB(binarize=False))\n",
    "classifier.train(X_train, y_train)\n",
    "accuracy = nltk.classify.accuracy(classifier, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "995bc007",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NaiveBayesClassifier\n\u001b[0;32m----> 3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mNaiveBayesClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/classify/naivebayes.py:210\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.train\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    206\u001b[0m fnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Count up how many times each feature value occurred, given\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# the label and featurename.\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m featureset, label \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets:\n\u001b[1;32m    211\u001b[0m     label_freqdist[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname, fval \u001b[38;5;129;01min\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;66;03m# Increment freq(fval|label, fname)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "857b5a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38094    [much, love, trains, stomach, movie, premise, ...\n",
       "40624    [good, ppv, like, wrestlemania, xx, years, lat...\n",
       "49425    [finding, right, words, everybody, problem, va...\n",
       "35734    [really, suprised, movie, get, higher, rating,...\n",
       "41708    [start, confessing, tend, really, enjoy, actio...\n",
       "                               ...                        \n",
       "11284    [shadow, magic, recaptures, joy, amazement, fi...\n",
       "44732    [found, movie, quite, enjoyable, fairly, enter...\n",
       "38158    [avoid, one, terrible, movie, exciting, pointl...\n",
       "860      [production, quite, surprise, absolutely, love...\n",
       "15795    [decent, movie, although, little, bit, short, ...\n",
       "Name: review_token, Length: 35000, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяю качество. Буду пробовать различные модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализирую анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197bc36",
   "metadata": {},
   "source": [
    "### Необходимо написать на базе BERT определитель жанра фильма: \n",
    " - На вход подается сюжет фильма. На выходе - жанр  ",
    "sample: https://www.kaggle.com/balraj98/movie-genre-prediction-from-wiki-plot-using-bert \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# клонирование берт\n",
    "# git clone https://github.com/google-research/bert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# model_args = {\n",
    "#     \"reprocess_input_data\": True,\n",
    "#     \"overwrite_output_dir\": True,\n",
    "#     \"save_model_every_epoch\": False,\n",
    "#     \"save_eval_checkpoints\": False,\n",
    "#     \"max_seq_length\": 512,\n",
    "#     \"train_batch_size\": 16,\n",
    "#     \"num_train_epochs\": 4,\n",
    "# }\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model = ClassificationModel('bert', 'bert-base-cased', num_labels=len(shortlisted_genres), args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e2ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Создание токенизатора BERT\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Подготовка Данных Для Обучения\n",
    "reviews_with_len = [[review, y[i], len(review)]\n",
    "                 for i, review in enumerate(tokenized_reviews)]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359554a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Создание модели\n",
    "\n",
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output\n",
    "\n",
    "\n",
    "#     гипперпараметры\n",
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5\n",
    "\n",
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилирование\n",
    "\n",
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  обучаем\n",
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  проверяем результат на тестовом наборе \n",
    "results = text_model.evaluate(test_dataset)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
